ðŸš€ RAG Q&A Application
This Retrieval-Augmented Generation (RAG) application allows users to ask questions based on different document types such as URLs, PDFs, text files, and DOCX. Powered by FAISS for vector retrieval and Hugging Face models for generating answers, this tool helps users quickly retrieve and understand information.

ðŸŒŸ Key Features
ðŸ“„ Multi-format Input: Supports data input from:
URLs
PDF files
DOCX files
Plain text files
âš¡ Fast & Accurate: Uses FAISS indexing and Hugging Face embeddings to ensure rapid and relevant results.
ðŸ¤– LLM Integration: Employs Hugging Face models to generate answers to user queries based on the provided documents.
ðŸ“š Core Functions
1. process_input(input_type, document_data)
Description: Processes different types of documents and splits them into chunks for embedding.
Inputs:
input_type (str): The format of the document (e.g., "Link", "PDF", "Text").
document_data (varies): The actual document data to process.
Output: FAISS vectorstore containing embedded document chunks.
python
Copy code
def process_input(input_type, document_data):
    # Function logic...
2. answer_question(vectorstore, query)
Description: Takes the userâ€™s query and retrieves an answer using the vectorstore and a language model.
Inputs:
vectorstore: The FAISS vectorstore generated from the document.
query (str): The question to be answered.
Output: A response generated by the language model.
python
Copy code
def answer_question(vectorstore, query):
    # Function logic...
3. main()
Description: The main function that controls the appâ€™s Streamlit interface.
Functionality:
Allows users to upload documents or input URLs.
Provides an interface to ask questions based on the uploaded data.
python
Copy code
def main():
    # Function logic...
